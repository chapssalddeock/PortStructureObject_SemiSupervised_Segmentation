{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":182399,"status":"ok","timestamp":1655640860923,"user":{"displayName":"김채원","userId":"10106580930662262577"},"user_tz":-540},"id":"Nzq8yHF3MPSp","outputId":"f9d42c76-8001-40bb-8d25-99cd7647dfac"},"outputs":[],"source":["!pip install pyyaml==5.1\n","!pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1023,"status":"ok","timestamp":1655640861934,"user":{"displayName":"김채원","userId":"10106580930662262577"},"user_tz":-540},"id":"OYihg2DHNlh4","outputId":"5061cc9f-dbd3-4f74-978c-77fb0b9a3f40"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n","torch:  1.11 ; cuda:  cu113\n","detectron2: 0.6\n"]}],"source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1018,"status":"ok","timestamp":1655640862939,"user":{"displayName":"김채원","userId":"10106580930662262577"},"user_tz":-540},"id":"eG-gV6UlNpO1"},"outputs":[],"source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt\n","import json\n","from pandas.io.json import json_normalize\n","import os\n","import torch\n","import copy\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultTrainer, DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.structures import BoxMode\n","from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n","from detectron2.data import detection_utils as utils\n","import detectron2.data.transforms as T\n","\n","from pycocotools.coco import COCO\n","import skimage.io as io\n","from detectron2.utils.visualizer import ColorMode\n","\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BSV6bF3sxQ9","outputId":"6fb14e97-b729-49b1-f4d7-2355ef5e079c"},"outputs":[],"source":["!pip uninstall albumentations\n","!pip install albumentations==1.1.0\n","!pip install \"opencv-python-headless<4.3\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Phor5Krs1Ju"},"outputs":[],"source":["import albumentations as A\n","print(A.__version__)#1.1.0"]},{"cell_type":"markdown","metadata":{},"source":["###  transform 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNbHLoDezSPE"},"outputs":[],"source":["import albumentations as A\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import random\n","random.seed(57)\n","\n","\n","train_transform_1 = A.Compose([\n","                             A.OneOf([\n","                                      A.HorizontalFlip(p=1),\n","                                      A.Rotate(limit=30, p=1),\n","                                      A.VerticalFlip(p=1),\n","                                      A.ColorJitter(p=1)                             \n","\n","                             ])]) # transform 기법 바꿔보기\n","\n","\n","train_transform_2 = A.Compose([\n","                            A.OneOf([\n","                                      A.HorizontalFlip(p=1),\n","                                      A.RandomRotate90(p=1), # 완전 뒤집힘 말고 45정도까지\n","                                      A.VerticalFlip(p=1)], p=1),\n","                            A.OneOf([\n","                                    A.GaussNoise(p=1),\n","                                    A.RandomBrightness(p=1),\n","                                    A.Blur(p=1)], p=0.7) # 블러 limit 낮추기\n","])\n","\n","\n","train_transform_3 = A.Compose([\n","                             A.OneOf([\n","                                      A.HorizontalFlip(p=1),\n","                                      A.RandomRotate90(p=1),\n","                                      A.VerticalFlip(p=1),\n","                                      ], p=1),]) # position 증강\n","\n","train_transform_4 = A.Compose([\n","                             A.Blur(blur_limit=[5,5], p=1)]) # blur 처리\n","\n","train_transfrom_5 =  A.Compose([\n","                             A.OneOf([\n","                                      A.Rotate(limit = [-45,45],p=1),\n","                                      A.VerticalFlip(p=1),\n","                                      ], p=1)\n","                             ])\n","\n","train_transfrom_6 =  A.Compose([\n","                             A.OneOf([\n","                                      A.Rotate(limit = [-45,45],p=1),\n","                                      A.HorizontalFlip(p=1),\n","                                      ], p=1)\n","                             ])"]},{"cell_type":"markdown","metadata":{},"source":["### 원본 파일 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxmZQwNH6vrI"},"outputs":[],"source":["import glob\n","import os\n","\n","label_img_lst = glob.glob(\"/개인정보 블라인드/train/labeled_images/\"+\"*.jpg\")\n","mask_lst = glob.glob(\"/개인정보 블라인드/train/labels/\"+\"*.png\")\n","\n","label_img_lst.sort()\n","mask_lst.sort()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1655637890828,"user":{"displayName":"이현석","userId":"13108008471658268838"},"user_tz":-540},"id":"c3na-ICBVXQ6","outputId":"ae3bca9d-4768-477c-a1dc-7a87b6223f42"},"outputs":[{"data":{"text/plain":["(135, 135)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(label_img_lst), len(mask_lst)"]},{"cell_type":"markdown","metadata":{},"source":["### 각 클래스 갯수 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWv4Vse6HS6q"},"outputs":[],"source":["container = 0\n","forklift = 0\n","reach_stacker = 0\n","ship = 0\n","\n","# 57은 이미지 경로 length, -15는 이미지 파일 이름 length\n","for idx, name in enumerate(label_img_lst):\n","  if label_img_lst[idx][57:-15] == 'container_truck':\n","    container += 1\n","  elif label_img_lst[idx][57:-15] == 'forklift':\n","    forklift += 1\n","  elif label_img_lst[idx][57:-15] == 'reach_stacker':\n","    reach_stacker += 1\n","  elif label_img_lst[idx][57:-15] == 'ship':\n","    ship += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1655637894621,"user":{"displayName":"이현석","userId":"13108008471658268838"},"user_tz":-540},"id":"ODRXZY21HTFF","outputId":"4a87e284-2652-4957-a87c-bc381380cda5"},"outputs":[{"name":"stdout","output_type":"stream","text":["32 37 13 53\n"]}],"source":["# 원래 갯수\n","print(container , forklift, reach_stacker,ship)"]},{"cell_type":"markdown","metadata":{"id":"qkM6aeukOcVh"},"source":["## Function 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFiVxqxKKGjn"},"outputs":[],"source":["# 이미지 불러와서 트랜스폼 버전에 맞게 이미지와 마스크를 변환 후 반환하는 함수\n","\n","def image_transform(item, mask, transfrom_version):\n","  im = cv2.imread(item)\n","  im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","  aug_mask = np.asarray(Image.open(mask))\n","\n","  transformed = transfrom_version(image=im, mask=aug_mask) \n","  transformed_image = transformed['image']\n","  transformed_mask = transformed['mask']\n","  \n","  return transformed_image,transformed_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJrrQOjCNcu-"},"outputs":[],"source":["import skimage.measure as measure\n","\n","def close_contour(contour):\n","  if not np.array_equal(contour[0], contour[-1]):\n","    contour = np.vstack((contour, contour[0]))\n","  return contour\n","\n","def binary_mask_to_polygon(binary_mask, tolerance=0):\n","  polygons = []\n","  # pad mask to close contours of shapes which start and end at an edge\n","  padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n","  contours = measure.find_contours(padded_binary_mask, 0.5)\n","  contours = np.subtract(contours, 1)\n","  for contour in contours:\n","      contour = close_contour(contour)\n","      contour = measure.approximate_polygon(contour, tolerance)\n","      if len(contour) < 3: \n","          continue\n","      contour = np.flip(contour, axis=1)\n","      segmentation = contour.ravel().tolist()\n","      # after padding and subtracting 1 we may get -0.5 points in our segmentation\n","      segmentation = [0 if i < 0 else i for i in segmentation]\n","      polygons.append(segmentation)\n","\n","  return polygons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFmUNTSaNh_j"},"outputs":[],"source":["classes = ['container_truck', 'forklift', 'reach_stacker', 'ship']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsRhw3-lKS1X"},"outputs":[],"source":["aug_img_lst = []\n","aug_mask_lst = []\n","sample_preds_folder = \"/개인정보 블라인드/\"\n","\n","# 증강 후 저장\n","for item, mask in zip(label_img_lst,mask_lst):\n","\n","  if item[57:-15] in ['forklift', 'container_truck']:\n","    transformed_image,transformed_mask = image_transform(item, mask,train_transform_1) # transform 버전 바꾸기!!!!!!!!!!!!!!!!!!!!!!\n","    aug_img_lst.append(transformed_image) #확인용\n","    aug_mask_lst.append(transformed_mask)\n","\n","    cv2.imwrite(os.path.join(sample_preds_folder,\"random_img/\",\"{}{}.jpg\".format(item[57:-5],i)),transformed_image) # 새로운 이미지 저장\n","    cv2.imwrite(os.path.join(sample_preds_folder,\"random_mask/\",\"{}{}.png\".format(item[57:-5],i)), transformed_mask)\n","\n","  if item[57:-15] == 'reach_stacker':\n","    for i in range(2):\n","      transformed_image,transformed_mask = image_transform(item, mask,train_transform_1) # transform 버전 바꾸기!!!!!!!!!!!!!!!!!!!!!!\n","      aug_img_lst.append(transformed_image) #확인용\n","      aug_mask_lst.append(transformed_mask)\n","\n","      cv2.imwrite(os.path.join(sample_preds_folder,\"random_img/\",\"{}{}.jpg\".format(item[57:-5],i)),transformed_image) # 새로운 이미지 저장\n","      cv2.imwrite(os.path.join(sample_preds_folder,\"random_mask/\",\"{}{}.png\".format(item[57:-5],i)), transformed_mask)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1655638015782,"user":{"displayName":"이현석","userId":"13108008471658268838"},"user_tz":-540},"id":"EytF-JOpRTsJ","outputId":"35101676-900d-4045-8f5c-03ba764808b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["32 37 26 0\n","95\n"]}],"source":["# 위에서 저장된 파일 불러오기\n","label_img_lst = glob.glob(f\"/개인정보 블라인드/random_img/\"+\"*.jpg\")\n","mask_lst = glob.glob(f\"/개인정보 블라인드/random_mask/\"+\"*.png\")\n","\n","label_img_lst.sort()\n","mask_lst.sort()\n","\n","container = 0\n","forklift = 0\n","reach_stacker = 0\n","ship = 0\n","\n","# 개수 세기 \n","for idx, name in enumerate(label_img_lst):\n","  if label_img_lst[idx][-30:-15] == 'container_truck':\n","    container += 1\n","  elif label_img_lst[idx][-23:-15] == 'forklift':\n","    forklift += 1\n","  elif label_img_lst[idx][-28:-15] == 'reach_stacker':\n","    reach_stacker += 1\n","  elif label_img_lst[idx][-19:-15] == 'ship':\n","    ship += 1\n","\n","print(container,forklift,  reach_stacker, ship)\n","print(container+forklift+reach_stacker+ship)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZdS023KNvY9"},"outputs":[],"source":["import os\n","import numpy as np\n","import json\n","from detectron2.structures import BoxMode\n","\n","\n","\n","num = len(\"/개인정보 블라인드/random_img/\")\n","\n","# 랜덤으로 변환된 이미지를 피클 파일로 저장하기 위함\n","\n","def get_port_dicts(file_name,label_name):\n","\n","    dataset_dicts = []\n","    for filename, labelname in zip(file_name,label_name):\n","\n","        record = {}\n","        objs = []\n","\n","        img = Image.open(filename) #사이즈 알려고 이미지 불러옴\n","\n","        record[\"file_name\"] = filename \n","        record[\"height\"] = img.size[1] #h  \n","        record[\"width\"] = img.size[0] #w\n","\n","        \n","        mask = np.asarray(Image.open(labelname)) # 마스크 이미지 불러옴\n","        ins_coords = binary_mask_to_polygon(mask) # 폴리곤으로 만듦\n","        if len(ins_coords) != 0 :\n","          px = [a for a in ins_coords[0][0::2]]\n","          py = [a for a in ins_coords[0][1::2]]\n","          poly = [[x, y] for x, y in zip(px, py)]\n","\n","          obj = {\n","            \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n","            \"bbox_mode\": BoxMode.XYXY_ABS,\n","            \"segmentation\": [poly],\n","            \"category_id\": classes.index(filename[num:-15]), # data path에서...슬라이싱...\n","            \"iscrowd\": 0\n","        }\n","\n","        objs.append(obj)\n","        record[\"annotations\"] = objs\n","        dataset_dicts.append(record)\n","\n","    return dataset_dicts"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1655638016279,"user":{"displayName":"이현석","userId":"13108008471658268838"},"user_tz":-540},"id":"q9y6lmblN3Lt","outputId":"c2c18edf-a882-49a7-c374-1af915f3521e"},"outputs":[],"source":["import glob\n","\n","img_lst = glob.glob(f\"/개인정보 블라인드/random_img/\"+\"*.jpg\")\n","mask_lst = glob.glob(f\"/개인정보 블라인드/random_mask/\"+\"*.png\")\n","\n","img_lst.sort()\n","mask_lst.sort()\n","\n","print(len(img_lst), len(mask_lst))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5961,"status":"ok","timestamp":1655638022231,"user":{"displayName":"이현석","userId":"13108008471658268838"},"user_tz":-540},"id":"G6XJMnCkO4Qs","outputId":"4cf348a2-fc6e-4d3e-b84f-8995bd751d82"},"outputs":[],"source":["aug_dataset = get_port_dicts(img_lst,mask_lst)\n","print(len(aug_dataset))\n","\n","import pickle\n","\n","with open('/개인정보 블라인드/aug.pickle', 'wb') as f:\n","    pickle.dump(aug_dataset, f)"]},{"cell_type":"markdown","metadata":{"id":"cPEu_6GtKTdR"},"source":["### Test 파일도 동일한 과정을 거침\n","단, mask는 존재하지 않고 img만 존재함"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_image_transform(item, transfrom_version):\n","  im = cv2.imread(item)\n","  im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","\n","  transformed = transfrom_version(image=im) # 여기 함수 변경\n","  transformed_image = transformed['image']\n","\n","  \n","  return transformed_image"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","import glob\n","random.seed(42)\n","label_img_lst = glob.glob(f\"/개인정보 블라인드/test/images/\"+\"*.jpg\")\n","\n","aug_img_lst = []\n","sample_preds_folder = \"/개인정보 블라인드/aut_test/test/\"\n","\n","\n","for item in tqdm(label_img_lst):\n","\n","    transformed_image = test_image_transform(item,train_transform_1)\n","    aug_img_lst.append(transformed_image) #확인용\n","   \n","\n","    cv2.imwrite(os.path.join(sample_preds_folder,\"{}.jpg\".format(item[48:-4])),transformed_image) # 새로운 이미지 저장\n","\n","print(len(aug_img_lst))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["j4Ja8pvcP19D","eJIdOLxmKTWc","SjNHknA0R_rR","cPEu_6GtKTdR","x7iBkHleKTfu"],"machine_shape":"hm","name":"200mask_data_augmentation.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
